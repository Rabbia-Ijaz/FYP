{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MotionTransfer.ipynb",
      "provenance": [],
      "mount_file_id": "1mH03ZxN_3SK5weOmfiDrFaZa0q2k-_MK",
      "authorship_tag": "ABX9TyPdUnztOHhKPoQnzNVbX62j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rabbia-Ijaz/TryItOut/blob/main/MotionTransfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UMzEMomiwZ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f9aaf4f-1d6f-407f-bbf9-1ea76e5590cb"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import glob\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "from IPython.display import display\n",
        "!pip install UVTextureConverter\n",
        "from UVTextureConverter import UVConverter\n",
        "from UVTextureConverter import Normal2Atlas\n",
        "from UVTextureConverter import Atlas2Normal"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting UVTextureConverter\n",
            "  Downloading UVTextureConverter-1.2.0-py3-none-any.whl (7.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.2 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from UVTextureConverter) (4.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from UVTextureConverter) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from UVTextureConverter) (1.19.5)\n",
            "Installing collected packages: UVTextureConverter\n",
            "Successfully installed UVTextureConverter-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3vW5Y9btiQp",
        "outputId": "ba1f0e9a-4916-416d-9b5c-823c9fb8fe65"
      },
      "source": [
        "import cv2\n",
        "vidcap = cv2.VideoCapture('/content/drive/MyDrive/Colab Notebooks/Try.mp4')\n",
        "imageArray=[]\n",
        "success,image = vidcap.read()\n",
        "imageArray.append(image)\n",
        "count = 0\n",
        "while success:\n",
        "  cv2.imwrite(\"frame%d.jpg\" % count, image)     # save frame as JPEG file      \n",
        "  vidcap.set(cv2.CAP_PROP_POS_MSEC,(count*1200))    # added this line\n",
        "  success,image = vidcap.read()\n",
        "  imageArray.append(image)\n",
        "  print('Read a new frame: ', count)\n",
        "  #plt.imshow(image)\n",
        "  count += 1\n",
        "print(len(imageArray))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read a new frame:  0\n",
            "Read a new frame:  1\n",
            "Read a new frame:  2\n",
            "Read a new frame:  3\n",
            "Read a new frame:  4\n",
            "Read a new frame:  5\n",
            "Read a new frame:  6\n",
            "Read a new frame:  7\n",
            "Read a new frame:  8\n",
            "Read a new frame:  9\n",
            "Read a new frame:  10\n",
            "12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXYTo-Pvjbvo"
      },
      "source": [
        "def Display(title1 ,a): #global display func\n",
        "    name=title1+'.jpg'\n",
        "    cv2.imwrite(name,a)\n",
        "    print(title1)\n",
        "    display(Image(filename=name))\n",
        "\n",
        "input=\"\"\n",
        "input_IUV=\"\"\n",
        "target=\"\"\n",
        "\n",
        "def Inputfunc(input_1,input_1_IUV,target_1,target_IUV):\n",
        "  \n",
        "  path=\"/content/drive/MyDrive/Colab Notebooks/\"\n",
        "  input=path+input_1\n",
        "  input_IUV=path+input_1_IUV\n",
        "  target=path+target_1\n",
        "  model_image = Image.open(path+input_1)\n",
        "  dense_image = Image.open(path+input_1_IUV)\n",
        "  model_image_1 = Image.open(path+target_1)\n",
        "  dense_image_1 = Image.open(path+target_IUV)\n",
        "  return input,target,input_IUV,model_image,dense_image,model_image_1,dense_image_1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqQ50N2ojb75"
      },
      "source": [
        "#input,target,input_IUV,model_image,dense_image,model_image_1,dense_image_1=Inputfunc(\"input_4.jpg\",\"input_4_IUV.png\",\"input_7.jpg\",\"input_7_IUV.png\")\n",
        "#input,target,input_IUV,model_image,dense_image,model_image_1,dense_image_1=Inputfunc(\"input_7.jpg\",\"input_7_IUV.png\",\"input_8.jpg\",\"input_8_IUV.png\")\n",
        "#input,target,input_IUV,model_image,dense_image,model_image_1,dense_image_1=Inputfunc(\"input_5.jpg\",\"input_5_IUV.png\",\"input_6.jpg\",\"input_6_IUV.png\")\n",
        "#input,target,input_IUV,model_image,dense_image,model_image_1,dense_image_1=Inputfunc(\"input_9.jpg\",\"input_9_IUV.png\",\"input_10.jpg\",\"input_10_IUV.png\")\n",
        "#input,target,input_IUV,model_image,dense_image,model_image_1,dense_image_1=Inputfunc(\"input_3.jpg\",\"input_3_IUV.png\",\"input_5.jpg\",\"input_5_IUV.png\")\n",
        "input,target,input_IUV,model_image,dense_image,model_image_1,dense_image_1=Inputfunc(\"input_2.jpg\",\"input_2_IUV.png\",\"input_3.jpg\",\"input_3_IUV.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSipm3SSjl-C"
      },
      "source": [
        "##**Source Image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPzijoGPjb86"
      },
      "source": [
        "dense_array = np.asarray(dense_image)\n",
        "model_dense=np.zeros(shape=(3,dense_array[:,:,0].shape[0],dense_array[:,:,0].shape[1]))\n",
        "model_dense[0]=dense_array[:,:,2]\n",
        "model_dense[1]=dense_array[:,:,1]\n",
        "model_dense[2]=dense_array[:,:,0]\n",
        "model_dense.shape\n",
        "model_array = np.asarray(model_image)[:model_dense.shape[1],:model_dense.shape[2],:]\n",
        "\n",
        "\n",
        "figure, axes = plt.subplots(nrows=1, ncols=4)\n",
        "axes.ravel()[0].imshow(model_array)\n",
        "axes.ravel()[0].set_axis_off()\n",
        "axes.ravel()[1].imshow(model_dense[0])\n",
        "axes.ravel()[1].set_axis_off()\n",
        "axes.ravel()[2].imshow(model_dense[1])\n",
        "axes.ravel()[2].set_axis_off()\n",
        "axes.ravel()[3].imshow(model_dense[2])\n",
        "axes.ravel()[3].set_axis_off()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S1UMbasjsjc"
      },
      "source": [
        "##**Target Image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA3CDQVHjcA8"
      },
      "source": [
        "dense_array_1 = np.asarray(dense_image_1)\n",
        "model_dense_1=np.zeros(shape=(3,dense_array_1[:,:,0].shape[0],dense_array_1[:,:,0].shape[1]))\n",
        "model_dense_1[0]=dense_array_1[:,:,2]\n",
        "model_dense_1[1]=dense_array_1[:,:,1]\n",
        "model_dense_1[2]=dense_array_1[:,:,0]\n",
        "model_dense_1.shape\n",
        "model_array_1 = np.asarray(model_image_1)[:model_dense_1.shape[1],:model_dense_1.shape[2],:]\n",
        "\n",
        "#display\n",
        "figure, axes = plt.subplots(nrows=1, ncols=4)\n",
        "axes.ravel()[0].imshow(model_array_1)\n",
        "axes.ravel()[0].set_axis_off()\n",
        "axes.ravel()[1].imshow(model_dense_1[0])\n",
        "axes.ravel()[1].set_axis_off()\n",
        "axes.ravel()[2].imshow(model_dense_1[1])\n",
        "axes.ravel()[2].set_axis_off()\n",
        "axes.ravel()[3].imshow(model_dense_1[2])\n",
        "axes.ravel()[3].set_axis_off()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOY6z_ixjcB4"
      },
      "source": [
        "solution = 75\n",
        "solution_float = float(solution) - 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5f40Ay0j8Zz"
      },
      "source": [
        "##**Texture Extraction from Source Image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vLnC_GrjcEq"
      },
      "source": [
        "U = model_dense[1, :, :]\n",
        "V = model_dense[2, :, :]\n",
        "parts = list()\n",
        "for PartInd in range(1, 25):\n",
        "    actual_part = np.zeros((solution, solution, 3))\n",
        "    x, y = np.where(model_dense[0,:,:] == PartInd)\n",
        "    if len(x) == 0:\n",
        "        parts.append(actual_part)\n",
        "        continue\n",
        "    u_current_points = U[x, y]\n",
        "    v_current_points = V[x, y]\n",
        "\n",
        "\n",
        "    tex_map_coords = ((255-v_current_points)*solution_float/255.).astype(int), (u_current_points*solution_float/255.).astype(int)\n",
        "    for c in range(3):\n",
        "        actual_part[tex_map_coords[0], tex_map_coords[1], c] = model_array[x, y, c]\n",
        "\n",
        "    parts.append(actual_part)\n",
        "\n",
        "\n",
        "tex_trans, mask_trans = UVConverter.create_texture(input, input_IUV, parts_size=solution, concat=False)\n",
        "\n",
        "# for display\n",
        "TextureIm = UVConverter.concat_atlas_tex(tex_trans)  # 800 x 1200 x 3\n",
        "plt.imshow(TextureIm)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7I99BDwjcG0"
      },
      "source": [
        "model_image_identity = model_array * np.expand_dims((model_dense[0] == 2)+(model_dense[0] == 15)+(model_dense[0] == 16)+(model_dense[0] == 17)+(model_dense[0] == 18)+(model_dense[0] == 19)+(model_dense[0] == 20)+ (model_dense[0] == 21)+(model_dense[0] == 22), 2)\n",
        "#plt.imshow(model_image_identity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9ThAgoEjcKD"
      },
      "source": [
        "np.array(parts).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R7Llp_EjcLK"
      },
      "source": [
        "IUV = model_dense\n",
        "\n",
        "I=model_dense[0,:,:]\n",
        "U = model_dense[1,:,:]\n",
        "V = model_dense[2,:,:]\n",
        "\n",
        "R_im = np.zeros(U.shape)\n",
        "G_im = np.zeros(U.shape)\n",
        "B_im = np.zeros(U.shape)\n",
        "\n",
        "for PartInd in range(1, 25):\n",
        "    tex = np.array(parts)[PartInd - 1, :, :, :].squeeze()\n",
        "    R = tex[:,:,0]\n",
        "    G = tex[:,:,1]\n",
        "    B = tex[:,:,2]\n",
        "    ###############\n",
        "    x,y = np.where(IUV[0,:,:]==PartInd)\n",
        "    u_current_points = U[x,y]   #  Pixels that belong to this specific part.\n",
        "    v_current_points = V[x,y]\n",
        "    ##\n",
        "    r_current_points = R[((255-v_current_points)*solution_float/255.).astype(int),(u_current_points*solution_float/255.).astype(int)]*255\n",
        "    g_current_points = G[((255-v_current_points)*solution_float/255.).astype(int),(u_current_points*solution_float/255.).astype(int)]*255\n",
        "    b_current_points = B[((255-v_current_points)*solution_float/255.).astype(int),(u_current_points*solution_float/255.).astype(int)]*255\n",
        "    ##  Get the RGB values from the texture images.\n",
        "    R_im[IUV[0,:,:]==PartInd] = r_current_points\n",
        "    G_im[IUV[0,:,:]==PartInd] = g_current_points\n",
        "    B_im[IUV[0,:,:]==PartInd] = b_current_points\n",
        "generated_image = np.concatenate((R_im[:,:,np.newaxis],G_im[:,:,np.newaxis],B_im[:,:,np.newaxis]), axis =2 ).astype(np.uint8)\n",
        "#generated_image.shape\n",
        "#plt.imshow(np.uint8(generated_image)*255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxmUEQ11kMZp"
      },
      "source": [
        "##**Image Synthesis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfbPbVISjcMJ"
      },
      "source": [
        "IUV = model_dense_1\n",
        "U = model_dense_1[1,:,:]\n",
        "V = model_dense_1[2,:,:]\n",
        "\n",
        "R_im = np.zeros(U.shape)\n",
        "G_im = np.zeros(U.shape)\n",
        "B_im = np.zeros(U.shape)\n",
        "\n",
        "for PartInd in range(1, 25):\n",
        "    tex = np.array(parts)[PartInd - 1, :, :, :].squeeze()\n",
        "    R = tex[:,:,0]\n",
        "    G = tex[:,:,1]\n",
        "    B = tex[:,:,2]\n",
        "    ###############\n",
        "    x,y = np.where(IUV[0,:,:]==PartInd)\n",
        "    u_current_points = U[x,y]   #  Pixels that belong to this specific part.\n",
        "    v_current_points = V[x,y]\n",
        "    ##\n",
        "    r_current_points = R[((255-v_current_points)*solution_float/255.).astype(int),(u_current_points*solution_float/255.).astype(int)]*255\n",
        "    g_current_points = G[((255-v_current_points)*solution_float/255.).astype(int),(u_current_points*solution_float/255.).astype(int)]*255\n",
        "    b_current_points = B[((255-v_current_points)*solution_float/255.).astype(int),(u_current_points*solution_float/255.).astype(int)]*255\n",
        "    ##  Get the RGB values from the texture images.\n",
        "    R_im[IUV[0,:,:]==PartInd] = r_current_points\n",
        "    G_im[IUV[0,:,:]==PartInd] = g_current_points\n",
        "    B_im[IUV[0,:,:]==PartInd] = b_current_points\n",
        "generated_image_1 = np.concatenate((R_im[:,:,np.newaxis],G_im[:,:,np.newaxis],B_im[:,:,np.newaxis]), axis =2 ).astype(np.uint8)\n",
        "\n",
        "plt.imshow(np.uint8(generated_image_1) * 255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMhR5euzkUgM"
      },
      "source": [
        "##**Extraction of the Important Part**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIZwpkFIjcNH"
      },
      "source": [
        "apparel_matrix = np.expand_dims((model_dense_1[0] == 2)+(model_dense_1[0] == 15)+(model_dense_1[0] == 16)+(model_dense_1[0] == 17)+(model_dense_1[0] == 18)+(model_dense_1[0] == 19)+(model_dense_1[0] == 20)+ (model_dense_1[0] == 21)+(model_dense_1[0] == 22), 2)\n",
        "\n",
        "apparel = generated_image_1 * apparel_matrix * 255\n",
        "plt.imshow(apparel)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIv8OofKjcOG"
      },
      "source": [
        "model_image_identity_1 = model_array_1 * np.logical_not(apparel_matrix)\n",
        "plt.imshow(model_image_identity_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9KHgyTSkemb"
      },
      "source": [
        "##**Extraction Mapping on Target Body**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeggF2SejcQH"
      },
      "source": [
        "FinalImage=model_image_identity_1 + apparel\n",
        "plt.imshow(FinalImage)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}